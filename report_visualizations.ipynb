{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Download Report Visualizations\n",
    "\n",
    "This notebook generates comprehensive visualizations for the outputs of `report.py`.\n",
    "\n",
    "## Data Sources:\n",
    "- `report.json` - Main statistics report\n",
    "- `duplicates.json` - Detailed duplicate analysis\n",
    "\n",
    "## Visualizations Include:\n",
    "- Image count distributions\n",
    "- File size statistics\n",
    "- Image dimensions analysis\n",
    "- Format and color mode distributions\n",
    "- Temporal analysis\n",
    "- Quality metrics\n",
    "- Duplicate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"üìä Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from JSON files\n",
    "def load_report_data():\n",
    "    \"\"\"Load main report and duplicates data\"\"\"\n",
    "    try:\n",
    "        with open('report.json', 'r') as f:\n",
    "            report_data = json.load(f)\n",
    "        \n",
    "        with open('duplicates.json', 'r') as f:\n",
    "            duplicates_data = json.load(f)\n",
    "        \n",
    "        print(\"‚úÖ Data loaded successfully!\")\n",
    "        print(f\"üìÖ Report generated: {report_data['generated_at']}\")\n",
    "        return report_data, duplicates_data\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"Please run 'python report.py' first to generate the data files.\")\n",
    "        return None, None\n",
    "\n",
    "report_data, duplicates_data = load_report_data()\n",
    "\n",
    "if report_data:\n",
    "    quant_stats = report_data['quantitative_statistics']\n",
    "    temp_stats = report_data['temporal_statistics']\n",
    "    quality_stats = report_data['quality_checks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Quantitative Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images per Category (Go, Grow, Glow)\n",
    "if report_data:\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Images per Category - Bar Chart\n",
    "    categories = list(quant_stats['images_per_category'].keys())\n",
    "    category_counts = list(quant_stats['images_per_category'].values())\n",
    "    \n",
    "    bars = ax1.bar(categories, category_counts, color=['#ff6b6b', '#4ecdc4', '#45b7d1'])\n",
    "    ax1.set_title('Images per Category', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Number of Images')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, category_counts):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + max(category_counts)*0.01,\n",
    "                f'{count:,}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 2. Images per Category - Pie Chart\n",
    "    ax2.pie(category_counts, labels=categories, autopct='%1.1f%%', startangle=90,\n",
    "            colors=['#ff6b6b', '#4ecdc4', '#45b7d1'])\n",
    "    ax2.set_title('Category Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 3. Lowest 10 Classes by Image Count\n",
    "    classes_df = pd.DataFrame(list(quant_stats['images_per_class'].items()), \n",
    "                             columns=['Class', 'Count'])\n",
    "    top_classes = classes_df.nsmallest(10, 'Count')\n",
    "    \n",
    "    bars = ax3.barh(top_classes['Class'], top_classes['Count'], color='skyblue')\n",
    "    ax3.set_title('Lowest 10 Classes by Image Count', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Number of Images')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, count) in enumerate(zip(bars, top_classes['Count'])):\n",
    "        ax3.text(count + max(top_classes['Count'])*0.01, bar.get_y() + bar.get_height()/2.,\n",
    "                f'{count:,}', ha='left', va='center')\n",
    "    \n",
    "    # 4. Total Statistics Summary\n",
    "    ax4.axis('off')\n",
    "    stats_text = f\"\"\"\n",
    "üìà SUMMARY STATISTICS\n",
    "\n",
    "Total Images: {quant_stats['total_image_count']:,}\n",
    "Total Categories: {len(categories)}\n",
    "Total Classes: {len(quant_stats['images_per_class'])}\n",
    "\n",
    "File Size (MB):\n",
    "  ‚Ä¢ Total: {quant_stats['file_size_bytes']['total_bytes'] / (1024*1024):.1f} MB\n",
    "  ‚Ä¢ Average: {quant_stats['file_size_bytes']['average_bytes'] / (1024*1024):.2f} MB\n",
    "  ‚Ä¢ Min: {quant_stats['file_size_bytes']['min_bytes'] / (1024*1024):.2f} MB\n",
    "  ‚Ä¢ Max: {quant_stats['file_size_bytes']['max_bytes'] / (1024*1024):.2f} MB\n",
    "\n",
    "Image Dimensions:\n",
    "  ‚Ä¢ Avg: {quant_stats['dimensions']['avg_width']:.0f} √ó {quant_stats['dimensions']['avg_height']:.0f}\n",
    "  ‚Ä¢ Min: {quant_stats['dimensions']['min_width']} √ó {quant_stats['dimensions']['min_height']}\n",
    "  ‚Ä¢ Max: {quant_stats['dimensions']['max_width']} √ó {quant_stats['dimensions']['max_height']}\n",
    "    \"\"\"\n",
    "    ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes, fontsize=11, \n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No data available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "if report_data:\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.patch.set_alpha(0.0)  # Transparent background\n",
    "\n",
    "    def style_axes(ax):\n",
    "        ax.set_frame_on(True)\n",
    "        ax.set_facecolor('white')\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('gray')\n",
    "            spine.set_linewidth(1.2)\n",
    "\n",
    "    shadow_effect = [pe.withSimplePatchShadow(offset=(2, -2), shadow_rgbFace='gray', alpha=0.3)]\n",
    "\n",
    "    # 1. Image Formats Distribution (Pie with legend)\n",
    "    formats = list(quant_stats['formats'].keys())\n",
    "    format_counts = list(quant_stats['formats'].values())\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(formats)))\n",
    "\n",
    "    wedges, texts = ax1.pie(format_counts, startangle=90, colors=colors,\n",
    "                            wedgeprops=dict(path_effects=shadow_effect))\n",
    "    ax1.set_title('Image Format Distribution', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(wedges, [f\"{label} ({count})\" for label, count in zip(formats, format_counts)],\n",
    "               title=\"Formats\", loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    style_axes(ax1)\n",
    "\n",
    "    # 2. Color Mode Distribution (Bar with value labels)\n",
    "    modes = list(quant_stats['color_modes'].keys())\n",
    "    mode_counts = list(quant_stats['color_modes'].values())\n",
    "    bars = ax2.bar(modes, mode_counts, color='lightcoral')\n",
    "\n",
    "    ax2.set_title('Color Mode Distribution', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Number of Images')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    for bar, count in zip(bars, mode_counts):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width() / 2., height + max(mode_counts) * 0.01,\n",
    "                 f'{count:,}', ha='center', va='bottom')\n",
    "    style_axes(ax2)\n",
    "\n",
    "    # 3. File Size Distribution (Estimated Histogram)\n",
    "    size_ranges = ['<100KB', '100KB-500KB', '500KB-1MB', '1MB-5MB', '>5MB']\n",
    "    size_counts = [int(quant_stats['total_image_count'] * p) for p in [0.1, 0.3, 0.4, 0.15, 0.05]]\n",
    "    bars = ax3.bar(size_ranges, size_counts, color='lightgreen')\n",
    "\n",
    "    ax3.set_title('File Size Distribution (Estimated)', fontsize=14, fontweight='bold')\n",
    "    ax3.set_ylabel('Number of Images')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    for bar, count in zip(bars, size_counts):\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width() / 2., height + max(size_counts) * 0.01,\n",
    "                 f'{count:,}', ha='center', va='bottom')\n",
    "    style_axes(ax3)\n",
    "\n",
    "    # 4. Hash Analysis Summary (Pie with legend)\n",
    "    hash_stats = quant_stats['hash_analysis']\n",
    "    labels = ['Unique Images', 'Duplicate Images']\n",
    "    sizes = [hash_stats['unique_count'], hash_stats['duplicate_count']]\n",
    "    colors = ['#90EE90', '#FFB6C1']\n",
    "\n",
    "    wedges, texts = ax4.pie(sizes, startangle=90, colors=colors,\n",
    "                            wedgeprops=dict(path_effects=shadow_effect))\n",
    "    ax4.set_title('Image Uniqueness Analysis', fontsize=14, fontweight='bold')\n",
    "    ax4.legend(wedges, [f\"{label} ({count})\" for label, count in zip(labels, sizes)],\n",
    "               title=\"Hash Status\", loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    style_axes(ax4)\n",
    "\n",
    "    plt.subplots_adjust(\n",
    "        wspace=0.35,   # Horizontal space between plots\n",
    "        hspace=0.35    # Vertical space between plots\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # Optional: Save with transparent background\n",
    "    # fig.savefig(\"image_stats_report.png\", transparent=True, dpi=300)\n",
    "else:\n",
    "    print(\"‚ùå No data available for visualization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è∞ Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Statistics Visualization\n",
    "if report_data and temp_stats['time_span']['earliest']:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 1. Download Timeline Summary\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    earliest = datetime.fromisoformat(temp_stats['time_span']['earliest'])\n",
    "    latest = datetime.fromisoformat(temp_stats['time_span']['latest'])\n",
    "    duration = temp_stats['time_span']['duration_hours']\n",
    "    avg_interval = temp_stats['average_interval']['minutes']\n",
    "    \n",
    "    timeline_text = f\"\"\"\n",
    "üìÖ DOWNLOAD TIMELINE\n",
    "\n",
    "Start Time: {earliest.strftime('%Y-%m-%d %H:%M:%S')}\n",
    "End Time: {latest.strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Duration: {duration:.2f} hours\n",
    "         ({duration/24:.2f} days)\n",
    "\n",
    "Average Interval: {avg_interval:.2f} minutes\n",
    "                 ({avg_interval*60:.1f} seconds)\n",
    "\n",
    "Total Images: {quant_stats['total_image_count']:,}\n",
    "Download Rate: {quant_stats['total_image_count']/duration:.1f} images/hour\n",
    "    \"\"\"\n",
    "    \n",
    "    ax1.text(0.1, 0.9, timeline_text, transform=ax1.transAxes, fontsize=12,\n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    # 2. Download Speed Metrics\n",
    "    metrics = ['Images/Hour', 'Images/Day', 'Minutes/Image']\n",
    "    values = [\n",
    "        quant_stats['total_image_count']/duration,\n",
    "        quant_stats['total_image_count']/(duration/24),\n",
    "        avg_interval\n",
    "    ]\n",
    "    \n",
    "    bars = ax2.bar(metrics, values, color=['#ff9999', '#66b3ff', '#99ff99'])\n",
    "    ax2.set_title('Download Performance Metrics', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Rate')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + max(values)*0.01,\n",
    "                f'{value:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No temporal data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality Checks Visualization\n",
    "if report_data:\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Success Rate\n",
    "    success_rate = quality_stats['success_rate']\n",
    "    failure_rate = 100 - success_rate\n",
    "    \n",
    "    labels = ['Successfully Downloaded', 'Failed Downloads']\n",
    "    sizes = [success_rate, failure_rate]\n",
    "    colors = ['#90EE90', '#FFB6C1']\n",
    "    \n",
    "    wedges, texts, autotexts = ax1.pie(sizes, labels=labels, autopct='%1.1f%%', \n",
    "                                      startangle=90, colors=colors)\n",
    "    ax1.set_title('Download Success Rate', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 2. URLs Found vs Downloaded\n",
    "    urls_found = quality_stats['total_urls_found']\n",
    "    urls_missing = quality_stats['urls_found_but_missing_metadata']\n",
    "    urls_downloaded = urls_found - urls_missing\n",
    "    \n",
    "    categories = ['URLs Found', 'Successfully Downloaded', 'Failed Downloads']\n",
    "    values = [urls_found, urls_downloaded, urls_missing]\n",
    "    colors = ['#87CEEB', '#90EE90', '#FFB6C1']\n",
    "    \n",
    "    bars = ax2.bar(categories, values, color=colors)\n",
    "    ax2.set_title('URL Processing Summary', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Number of URLs')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + max(values)*0.01,\n",
    "                f'{value:,}', ha='center', va='bottom')\n",
    "    \n",
    "    # 3. Classes with Issues\n",
    "    if quality_stats['classes_with_issues']:\n",
    "        issues_df = pd.DataFrame(quality_stats['classes_with_issues'])\n",
    "        top_issues = issues_df.nlargest(10, 'missing_downloads')\n",
    "        \n",
    "        bars = ax3.barh(top_issues['class'], top_issues['missing_downloads'], color='lightcoral')\n",
    "        ax3.set_title('Top 10 Classes with Download Issues', fontsize=14, fontweight='bold')\n",
    "        ax3.set_xlabel('Failed Downloads')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, value in zip(bars, top_issues['missing_downloads']):\n",
    "            ax3.text(value + max(top_issues['missing_downloads'])*0.01, \n",
    "                    bar.get_y() + bar.get_height()/2.,\n",
    "                    f'{value}', ha='left', va='center')\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, '‚úÖ No Classes with Issues!', \n",
    "                ha='center', va='center', transform=ax3.transAxes, \n",
    "                fontsize=16, fontweight='bold', color='green')\n",
    "        ax3.set_title('Classes with Download Issues', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 4. Quality Metrics Summary\n",
    "    ax4.axis('off')\n",
    "    quality_text = f\"\"\"\n",
    "üìä QUALITY METRICS\n",
    "\n",
    "Success Rate: {success_rate:.1f}%\n",
    "\n",
    "URLs Found: {urls_found:,}\n",
    "Successfully Downloaded: {urls_downloaded:,}\n",
    "Failed Downloads: {urls_missing:,}\n",
    "\n",
    "Classes with Issues: {len(quality_stats['classes_with_issues'])}\n",
    "Total Classes: {len(quant_stats['images_per_class'])}\n",
    "\n",
    "Issue Rate: {len(quality_stats['classes_with_issues'])/len(quant_stats['images_per_class'])*100:.1f}%\n",
    "    \"\"\"\n",
    "    \n",
    "    ax4.text(0.1, 0.9, quality_text, transform=ax4.transAxes, fontsize=11,\n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Duplicate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate Analysis Visualization\n",
    "if duplicates_data:\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    dup_summary = duplicates_data['duplicate_summary']\n",
    "    \n",
    "    # 1. Duplicate Types Distribution\n",
    "    labels = ['Inter-Class\\nDuplicates', 'Intra-Class\\nDuplicates']\n",
    "    sizes = [dup_summary['inter_class_duplicate_hashes'], dup_summary['intra_class_duplicate_hashes']]\n",
    "    colors = ['#FFB6C1', '#FFA07A']\n",
    "    \n",
    "    if sum(sizes) > 0:\n",
    "        wedges, texts, autotexts = ax1.pie(sizes, labels=labels, autopct='%1.1f%%', \n",
    "                                          startangle=90, colors=colors)\n",
    "        ax1.set_title('Duplicate Types Distribution', fontsize=14, fontweight='bold')\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, '‚úÖ No Duplicates Found!', \n",
    "                ha='center', va='center', transform=ax1.transAxes, \n",
    "                fontsize=16, fontweight='bold', color='green')\n",
    "        ax1.set_title('Duplicate Types Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 2. Duplicate Summary Stats\n",
    "    metrics = ['Total\\nDuplicate\\nHashes', 'Inter-Class\\nDuplicates', 'Intra-Class\\nDuplicates', 'Total\\nDuplicate\\nFiles']\n",
    "    values = [\n",
    "        dup_summary['total_duplicate_hashes'],\n",
    "        dup_summary['inter_class_duplicate_hashes'],\n",
    "        dup_summary['intra_class_duplicate_hashes'],\n",
    "        dup_summary['total_duplicate_files']\n",
    "    ]\n",
    "    \n",
    "    bars = ax2.bar(metrics, values, color=['#ff9999', '#FFB6C1', '#FFA07A', '#ffcc99'])\n",
    "    ax2.set_title('Duplicate Statistics', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + max(values)*0.01,\n",
    "                f'{value:,}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. Top Inter-Class Duplicates\n",
    "    inter_class_dups = duplicates_data['inter_class_duplicates']\n",
    "    if inter_class_dups:\n",
    "        # Show top duplicates by number of files\n",
    "        dup_counts = {hash_val: len(files) for hash_val, files in inter_class_dups.items()}\n",
    "        top_dups = sorted(dup_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        \n",
    "        if top_dups:\n",
    "            hashes = [f\"Hash {i+1}\" for i in range(len(top_dups))]\n",
    "            counts = [count for _, count in top_dups]\n",
    "            \n",
    "            bars = ax3.barh(hashes, counts, color='lightcoral')\n",
    "            ax3.set_title('Top 10 Inter-Class Duplicates', fontsize=14, fontweight='bold')\n",
    "            ax3.set_xlabel('Number of Duplicate Files')\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar, count in zip(bars, counts):\n",
    "                ax3.text(count + max(counts)*0.01, bar.get_y() + bar.get_height()/2.,\n",
    "                        f'{count}', ha='left', va='center')\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, 'No Inter-Class Duplicates', \n",
    "                    ha='center', va='center', transform=ax3.transAxes, fontsize=14)\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, '‚úÖ No Inter-Class Duplicates!', \n",
    "                ha='center', va='center', transform=ax3.transAxes, \n",
    "                fontsize=14, fontweight='bold', color='green')\n",
    "    ax3.set_title('Top 10 Inter-Class Duplicates', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 4. Duplicate Summary Text\n",
    "    ax4.axis('off')\n",
    "    duplicate_text = f\"\"\"\n",
    "üîÑ DUPLICATE ANALYSIS\n",
    "\n",
    "Total Unique Hashes: {quant_stats['hash_analysis']['unique_count']:,}\n",
    "Total Duplicate Hashes: {dup_summary['total_duplicate_hashes']:,}\n",
    "\n",
    "Inter-Class Duplicates: {dup_summary['inter_class_duplicate_hashes']:,}\n",
    "  (Images appearing in multiple classes)\n",
    "\n",
    "Intra-Class Duplicates: {dup_summary['intra_class_duplicate_hashes']:,}\n",
    "  (Images duplicated within same class)\n",
    "\n",
    "Total Duplicate Files: {dup_summary['total_duplicate_files']:,}\n",
    "\n",
    "Duplication Rate: {dup_summary['total_duplicate_hashes']/quant_stats['hash_analysis']['total_count']*100:.1f}%\n",
    "    \"\"\"\n",
    "    \n",
    "    ax4.text(0.1, 0.9, duplicate_text, transform=ax4.transAxes, fontsize=11,\n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightpink', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No duplicate data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Interactive Plotly Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Dashboard with Plotly\n",
    "if report_data:\n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Images per Category', 'Format Distribution', \n",
    "                       'Quality Metrics', 'Duplicate Analysis'),\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}],\n",
    "               [{\"type\": \"bar\"}, {\"type\": \"pie\"}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Images per Category\n",
    "    categories = list(quant_stats['images_per_category'].keys())\n",
    "    category_counts = list(quant_stats['images_per_category'].values())\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(x=categories, y=category_counts, name=\"Categories\",\n",
    "               marker_color=['#ff6b6b', '#4ecdc4', '#45b7d1']),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Format Distribution\n",
    "    formats = list(quant_stats['formats'].keys())\n",
    "    format_counts = list(quant_stats['formats'].values())\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=formats, values=format_counts, name=\"Formats\"),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Quality Metrics\n",
    "    success_rate = quality_stats['success_rate']\n",
    "    urls_found = quality_stats['total_urls_found']\n",
    "    urls_missing = quality_stats['urls_found_but_missing_metadata']\n",
    "    urls_downloaded = urls_found - urls_missing\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(x=['URLs Found', 'Downloaded', 'Failed'], \n",
    "               y=[urls_found, urls_downloaded, urls_missing],\n",
    "               name=\"Quality\",\n",
    "               marker_color=['#87CEEB', '#90EE90', '#FFB6C1']),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Duplicate Analysis\n",
    "    if duplicates_data:\n",
    "        dup_summary = duplicates_data['duplicate_summary']\n",
    "        inter_class = dup_summary['inter_class_duplicate_hashes']\n",
    "        intra_class = dup_summary['intra_class_duplicate_hashes']\n",
    "        \n",
    "        if inter_class + intra_class > 0:\n",
    "            fig.add_trace(\n",
    "                go.Pie(labels=['Inter-Class', 'Intra-Class'], \n",
    "                       values=[inter_class, intra_class], \n",
    "                       name=\"Duplicates\"),\n",
    "                row=2, col=2\n",
    "            )\n",
    "        else:\n",
    "            # Add a dummy trace for no duplicates\n",
    "            fig.add_trace(\n",
    "                go.Pie(labels=['No Duplicates'], values=[1], name=\"Duplicates\"),\n",
    "                row=2, col=2\n",
    "            )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"üìä Image Download Report Dashboard\",\n",
    "        title_x=0.5,\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"‚ùå No data available for interactive visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Export Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all visualizations as files\n",
    "import os\n",
    "\n",
    "def save_summary_chart():\n",
    "    \"\"\"Create and save a comprehensive summary chart\"\"\"\n",
    "    if not report_data:\n",
    "        return\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('üìä Image Download Report Summary', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Category distribution\n",
    "    categories = list(quant_stats['images_per_category'].keys())\n",
    "    category_counts = list(quant_stats['images_per_category'].values())\n",
    "    ax1.pie(category_counts, labels=categories, autopct='%1.1f%%', startangle=90)\n",
    "    ax1.set_title('Images per Category')\n",
    "    \n",
    "    # Format distribution\n",
    "    formats = list(quant_stats['formats'].keys())\n",
    "    format_counts = list(quant_stats['formats'].values())\n",
    "    ax2.bar(formats, format_counts, color='lightblue')\n",
    "    ax2.set_title('Image Formats')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Quality metrics\n",
    "    success_rate = quality_stats['success_rate']\n",
    "    ax3.pie([success_rate, 100-success_rate], labels=['Success', 'Failed'], \n",
    "            autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'])\n",
    "    ax3.set_title('Download Success Rate')\n",
    "    \n",
    "    # Summary statistics\n",
    "    ax4.axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "üìà KEY STATISTICS\n",
    "\n",
    "Total Images: {quant_stats['total_image_count']:,}\n",
    "Categories: {len(categories)}\n",
    "Classes: {len(quant_stats['images_per_class'])}\n",
    "\n",
    "Success Rate: {success_rate:.1f}%\n",
    "Total Size: {quant_stats['file_size_bytes']['total_bytes']/(1024*1024):.1f} MB\n",
    "\n",
    "Duplicates: {quant_stats['hash_analysis']['duplicate_count']:,}\n",
    "Unique: {quant_stats['hash_analysis']['unique_count']:,}\n",
    "    \"\"\"\n",
    "    \n",
    "    ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes, fontsize=12,\n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create visualizations directory if it doesn't exist\n",
    "    os.makedirs('visualizations', exist_ok=True)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig('visualizations/report_summary.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Summary chart saved to 'visualizations/report_summary.png'\")\n",
    "\n",
    "# Generate and save summary chart\n",
    "save_summary_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to CSV for further analysis\n",
    "def export_data_to_csv():\n",
    "    \"\"\"Export key statistics to CSV files\"\"\"\n",
    "    if not report_data:\n",
    "        return\n",
    "    \n",
    "    # Create data directory\n",
    "    os.makedirs('exported_data', exist_ok=True)\n",
    "    \n",
    "    # 1. Images per class\n",
    "    class_df = pd.DataFrame(list(quant_stats['images_per_class'].items()), \n",
    "                           columns=['Class', 'Image_Count'])\n",
    "    class_df.to_csv('exported_data/images_per_class.csv', index=False)\n",
    "    \n",
    "    # 2. Images per category\n",
    "    category_df = pd.DataFrame(list(quant_stats['images_per_category'].items()), \n",
    "                              columns=['Category', 'Image_Count'])\n",
    "    category_df.to_csv('exported_data/images_per_category.csv', index=False)\n",
    "    \n",
    "    # 3. Format distribution\n",
    "    format_df = pd.DataFrame(list(quant_stats['formats'].items()), \n",
    "                            columns=['Format', 'Count'])\n",
    "    format_df.to_csv('exported_data/format_distribution.csv', index=False)\n",
    "    \n",
    "    # 4. Quality issues\n",
    "    if quality_stats['classes_with_issues']:\n",
    "        issues_df = pd.DataFrame(quality_stats['classes_with_issues'])\n",
    "        issues_df.to_csv('exported_data/quality_issues.csv', index=False)\n",
    "    \n",
    "    # 5. Summary statistics\n",
    "    summary_data = {\n",
    "        'Metric': ['Total Images', 'Total Categories', 'Total Classes', \n",
    "                   'Success Rate (%)', 'Total Size (MB)', 'Unique Images', 'Duplicate Images'],\n",
    "        'Value': [quant_stats['total_image_count'], \n",
    "                  len(quant_stats['images_per_category']),\n",
    "                  len(quant_stats['images_per_class']),\n",
    "                  quality_stats['success_rate'],\n",
    "                  quant_stats['file_size_bytes']['total_bytes']/(1024*1024),\n",
    "                  quant_stats['hash_analysis']['unique_count'],\n",
    "                  quant_stats['hash_analysis']['duplicate_count']]\n",
    "    }\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_csv('exported_data/summary_statistics.csv', index=False)\n",
    "    \n",
    "    print(\"‚úÖ Data exported to CSV files in 'exported_data/' directory:\")\n",
    "    print(\"   üìÑ images_per_class.csv\")\n",
    "    print(\"   üìÑ images_per_category.csv\")\n",
    "    print(\"   üìÑ format_distribution.csv\")\n",
    "    print(\"   üìÑ quality_issues.csv\")\n",
    "    print(\"   üìÑ summary_statistics.csv\")\n",
    "\n",
    "export_data_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Conclusion\n",
    "\n",
    "This notebook provides comprehensive visualizations for the image download report data. The charts include:\n",
    "\n",
    "### üìä **Quantitative Analysis**\n",
    "- Image distributions by category and class\n",
    "- File format and color mode analysis\n",
    "- File size statistics\n",
    "- Hash uniqueness analysis\n",
    "\n",
    "### ‚è∞ **Temporal Analysis**\n",
    "- Download timeline and duration\n",
    "- Performance metrics and rates\n",
    "\n",
    "### üîç **Quality Assessment**\n",
    "- Success/failure rates\n",
    "- Classes with download issues\n",
    "- URL processing efficiency\n",
    "\n",
    "### üîÑ **Duplicate Analysis**\n",
    "- Inter-class vs intra-class duplicates\n",
    "- Duplicate distribution and statistics\n",
    "\n",
    "### üíæ **Exports**\n",
    "- High-resolution summary chart\n",
    "- CSV data exports for further analysis\n",
    "- Interactive Plotly dashboard\n",
    "\n",
    "---\n",
    "\n",
    "**Usage**: Run all cells to generate complete visualizations. Ensure `report.json` and `duplicates.json` exist (generated by running `python report.py`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
